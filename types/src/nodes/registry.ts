// =============================================================================
// NODE DEFINITION & REGISTRY
// =============================================================================

import type { NodeCategory, NodeType } from './base';
import type { HandleDefinition } from './handles';
import type { WorkflowNodeData } from './union';

export interface NodeDefinition {
  type: NodeType;
  label: string;
  description: string;
  category: NodeCategory;
  icon: string;
  inputs: HandleDefinition[];
  outputs: HandleDefinition[];
  defaultData: Partial<WorkflowNodeData>;
}

// =============================================================================
// NODE REGISTRY
// =============================================================================

export const NODE_DEFINITIONS: Record<NodeType, NodeDefinition> = {
  // Input nodes
  imageInput: {
    type: 'imageInput',
    label: 'Image',
    description: 'Upload or reference an image',
    category: 'input',
    icon: 'Image',
    inputs: [],
    outputs: [{ id: 'image', type: 'image', label: 'Image' }],
    defaultData: {
      label: 'Image',
      status: 'idle',
      image: null,
      filename: null,
      dimensions: null,
      source: 'upload',
    },
  },
  prompt: {
    type: 'prompt',
    label: 'Prompt',
    description: 'Text prompt for AI generation',
    category: 'input',
    icon: 'MessageSquare',
    inputs: [],
    outputs: [{ id: 'text', type: 'text', label: 'Prompt' }],
    defaultData: {
      label: 'Prompt',
      status: 'idle',
      prompt: '',
      variables: {},
    },
  },
  audioInput: {
    type: 'audioInput',
    label: 'Audio',
    description: 'Upload an audio file (MP3, WAV)',
    category: 'input',
    icon: 'Volume2',
    inputs: [],
    outputs: [{ id: 'audio', type: 'audio', label: 'Audio' }],
    defaultData: {
      label: 'Audio',
      status: 'idle',
      audio: null,
      filename: null,
      duration: null,
      source: 'upload',
    },
  },
  videoInput: {
    type: 'videoInput',
    label: 'Video',
    description: 'Upload or reference a video file',
    category: 'input',
    icon: 'FileVideo',
    inputs: [],
    outputs: [{ id: 'video', type: 'video', label: 'Video' }],
    defaultData: {
      label: 'Video',
      status: 'idle',
      video: null,
      filename: null,
      duration: null,
      dimensions: null,
      source: 'upload',
    },
  },
  promptConstructor: {
    type: 'promptConstructor',
    label: 'Prompt Constructor',
    description: 'Template-based prompt with @variable interpolation from connected Prompt nodes',
    category: 'input',
    icon: 'Puzzle',
    inputs: [{ id: 'text', type: 'text', label: 'Variables', multiple: true }],
    outputs: [{ id: 'text', type: 'text', label: 'Prompt' }],
    defaultData: {
      label: 'Prompt Constructor',
      status: 'idle',
      template: '',
      outputText: null,
      unresolvedVars: [],
    },
  },
  // AI nodes
  imageGen: {
    type: 'imageGen',
    label: 'Image Generator',
    description: 'Generate images with nano-banana models',
    category: 'ai',
    icon: 'Sparkles',
    inputs: [
      { id: 'prompt', type: 'text', label: 'Prompt', required: true },
      { id: 'images', type: 'image', label: 'Reference Images', multiple: true },
    ],
    outputs: [{ id: 'image', type: 'image', label: 'Generated Image' }],
    defaultData: {
      label: 'Image Generator',
      status: 'idle',
      inputImages: [],
      inputPrompt: null,
      outputImage: null,
      outputImages: [],
      model: 'nano-banana-pro',
      aspectRatio: '1:1',
      resolution: '2K',
      outputFormat: 'jpg',
      jobId: null,
    },
  },
  videoGen: {
    type: 'videoGen',
    label: 'Video Generator',
    description: 'Generate videos with veo-3.1 models',
    category: 'ai',
    icon: 'Video',
    inputs: [
      { id: 'prompt', type: 'text', label: 'Prompt', required: true },
      { id: 'image', type: 'image', label: 'Starting Frame' },
      { id: 'lastFrame', type: 'image', label: 'Last Frame (interpolation)' },
    ],
    outputs: [{ id: 'video', type: 'video', label: 'Generated Video' }],
    defaultData: {
      label: 'Video Generator',
      status: 'idle',
      inputImage: null,
      lastFrame: null,
      referenceImages: [],
      inputPrompt: null,
      negativePrompt: '',
      outputVideo: null,
      model: 'veo-3.1-fast',
      duration: 8,
      aspectRatio: '16:9',
      resolution: '1080p',
      generateAudio: true,
      jobId: null,
    },
  },
  llm: {
    type: 'llm',
    label: 'LLM',
    description: 'Generate text with meta-llama',
    category: 'ai',
    icon: 'Brain',
    inputs: [{ id: 'prompt', type: 'text', label: 'Prompt', required: true }],
    outputs: [{ id: 'text', type: 'text', label: 'Generated Text' }],
    defaultData: {
      label: 'LLM',
      status: 'idle',
      inputPrompt: null,
      outputText: null,
      model: 'meta-llama-3.1-405b-instruct',
      systemPrompt: 'You are a creative assistant helping generate content prompts.',
      temperature: 0.7,
      maxTokens: 1024,
      topP: 0.9,
      jobId: null,
    },
  },
  lipSync: {
    type: 'lipSync',
    label: 'Lip Sync',
    description: 'Generate talking-head video from image/video and audio using Replicate',
    category: 'ai',
    icon: 'Mic',
    inputs: [
      { id: 'image', type: 'image', label: 'Face Image' },
      { id: 'video', type: 'video', label: 'Source Video' },
      { id: 'audio', type: 'audio', label: 'Audio', required: true },
    ],
    outputs: [{ id: 'video', type: 'video', label: 'Generated Video' }],
    defaultData: {
      label: 'Lip Sync',
      status: 'idle',
      inputImage: null,
      inputVideo: null,
      inputAudio: null,
      outputVideo: null,
      model: 'sync/lipsync-2',
      syncMode: 'loop',
      temperature: 0.5,
      activeSpeaker: false,
      jobId: null,
    },
  },
  voiceChange: {
    type: 'voiceChange',
    label: 'Voice Change',
    description: 'Replace or mix audio track in a video',
    category: 'ai',
    icon: 'AudioLines',
    inputs: [
      { id: 'video', type: 'video', label: 'Video', required: true },
      { id: 'audio', type: 'audio', label: 'New Audio', required: true },
    ],
    outputs: [{ id: 'video', type: 'video', label: 'Output Video' }],
    defaultData: {
      label: 'Voice Change',
      status: 'idle',
      inputVideo: null,
      inputAudio: null,
      outputVideo: null,
      preserveOriginalAudio: false,
      audioMixLevel: 0.5,
      jobId: null,
    },
  },
  textToSpeech: {
    type: 'textToSpeech',
    label: 'Text to Speech',
    description: 'Convert text to natural-sounding speech using ElevenLabs',
    category: 'ai',
    icon: 'AudioLines',
    inputs: [{ id: 'text', type: 'text', label: 'Text', required: true }],
    outputs: [{ id: 'audio', type: 'audio', label: 'Audio' }],
    defaultData: {
      label: 'Text to Speech',
      status: 'idle',
      inputText: null,
      outputAudio: null,
      provider: 'elevenlabs',
      voice: 'rachel',
      stability: 0.5,
      similarityBoost: 0.75,
      speed: 1.0,
      jobId: null,
    },
  },
  transcribe: {
    type: 'transcribe',
    label: 'Transcribe',
    description: 'Convert video or audio to text transcript',
    category: 'ai',
    icon: 'FileText',
    inputs: [
      { id: 'video', type: 'video', label: 'Video' },
      { id: 'audio', type: 'audio', label: 'Audio' },
    ],
    outputs: [{ id: 'text', type: 'text', label: 'Transcript' }],
    defaultData: {
      label: 'Transcribe',
      status: 'idle',
      inputVideo: null,
      inputAudio: null,
      outputText: null,
      language: 'auto',
      timestamps: false,
      jobId: null,
    },
  },

  motionControl: {
    type: 'motionControl',
    label: 'Motion Control',
    description: 'Generate video with precise motion control using Kling AI',
    category: 'ai',
    icon: 'Navigation',
    inputs: [
      { id: 'image', type: 'image', label: 'Image', required: true },
      { id: 'video', type: 'video', label: 'Motion Video' },
      { id: 'prompt', type: 'text', label: 'Prompt' },
    ],
    outputs: [{ id: 'video', type: 'video', label: 'Video' }],
    defaultData: {
      label: 'Motion Control',
      status: 'idle',
      inputImage: null,
      inputVideo: null,
      inputPrompt: null,
      outputVideo: null,
      mode: 'video_transfer',
      duration: 5,
      aspectRatio: '16:9',
      trajectoryPoints: [],
      cameraMovement: 'static',
      cameraIntensity: 50,
      qualityMode: 'pro',
      characterOrientation: 'image',
      keepOriginalSound: true,
      motionStrength: 50,
      negativePrompt: '',
      seed: null,
      jobId: null,
    },
  },

  // Processing nodes
  resize: {
    type: 'resize',
    label: 'Resize',
    description: 'Resize images or videos to different aspect ratios using Luma AI',
    category: 'processing',
    icon: 'Maximize2',
    inputs: [{ id: 'media', type: 'image', label: 'Media', required: true }],
    outputs: [{ id: 'media', type: 'image', label: 'Resized Media' }],
    defaultData: {
      label: 'Resize',
      status: 'idle',
      inputMedia: null,
      inputType: null,
      outputMedia: null,
      targetAspectRatio: '16:9',
      prompt: '',
      gridPosition: { x: 0.5, y: 0.5 },
      jobId: null,
    },
  },
  animation: {
    type: 'animation',
    label: 'Animation',
    description: 'Apply easing curve to video',
    category: 'processing',
    icon: 'Wand2',
    inputs: [{ id: 'video', type: 'video', label: 'Video', required: true }],
    outputs: [{ id: 'video', type: 'video', label: 'Animated Video' }],
    defaultData: {
      label: 'Animation',
      status: 'idle',
      inputVideo: null,
      outputVideo: null,
      curveType: 'preset',
      preset: 'easeInOutCubic',
      customCurve: [0.645, 0.045, 0.355, 1],
      speedMultiplier: 1,
    },
  },
  videoStitch: {
    type: 'videoStitch',
    label: 'Video Stitch',
    description: 'Concatenate multiple videos',
    category: 'processing',
    icon: 'Layers',
    inputs: [{ id: 'videos', type: 'video', label: 'Videos', multiple: true, required: true }],
    outputs: [{ id: 'video', type: 'video', label: 'Stitched Video' }],
    defaultData: {
      label: 'Video Stitch',
      status: 'idle',
      inputVideos: [],
      outputVideo: null,
      transitionType: 'crossfade',
      transitionDuration: 0.5,
      seamlessLoop: false,
    },
  },
  videoTrim: {
    type: 'videoTrim',
    label: 'Video Trim',
    description: 'Trim video to a specific time range',
    category: 'processing',
    icon: 'Scissors',
    inputs: [{ id: 'video', type: 'video', label: 'Video', required: true }],
    outputs: [{ id: 'video', type: 'video', label: 'Trimmed Video' }],
    defaultData: {
      label: 'Video Trim',
      status: 'idle',
      inputVideo: null,
      outputVideo: null,
      startTime: 0,
      endTime: 60,
      duration: null,
      jobId: null,
    },
  },
  videoFrameExtract: {
    type: 'videoFrameExtract',
    label: 'Frame Extract',
    description: 'Extract a specific frame from video as image',
    category: 'processing',
    icon: 'Film',
    inputs: [{ id: 'video', type: 'video', label: 'Video', required: true }],
    outputs: [{ id: 'image', type: 'image', label: 'Extracted Frame' }],
    defaultData: {
      label: 'Frame Extract',
      status: 'idle',
      inputVideo: null,
      outputImage: null,
      selectionMode: 'last',
      timestampSeconds: 0,
      percentagePosition: 100,
      videoDuration: null,
      jobId: null,
    },
  },
  reframe: {
    type: 'reframe',
    label: 'Reframe',
    description: 'Reframe images or videos to different aspect ratios with AI outpainting',
    category: 'processing',
    icon: 'Crop',
    inputs: [
      { id: 'image', type: 'image', label: 'Image' },
      { id: 'video', type: 'video', label: 'Video' },
    ],
    outputs: [
      { id: 'image', type: 'image', label: 'Reframed Image' },
      { id: 'video', type: 'video', label: 'Reframed Video' },
    ],
    defaultData: {
      label: 'Reframe',
      status: 'idle',
      inputImage: null,
      inputVideo: null,
      inputType: null,
      outputImage: null,
      outputVideo: null,
      model: 'photon-flash-1',
      aspectRatio: '16:9',
      prompt: '',
      gridPosition: { x: 0.5, y: 0.5 },
      jobId: null,
    },
  },
  upscale: {
    type: 'upscale',
    label: 'Upscale',
    description: 'AI-powered upscaling for images and videos',
    category: 'processing',
    icon: 'Maximize',
    inputs: [
      { id: 'image', type: 'image', label: 'Image' },
      { id: 'video', type: 'video', label: 'Video' },
    ],
    outputs: [
      { id: 'image', type: 'image', label: 'Upscaled Image' },
      { id: 'video', type: 'video', label: 'Upscaled Video' },
    ],
    defaultData: {
      label: 'Upscale',
      status: 'idle',
      inputImage: null,
      inputVideo: null,
      inputType: null,
      outputImage: null,
      outputVideo: null,
      originalPreview: null,
      outputPreview: null,
      model: 'topaz-standard-v2',
      upscaleFactor: '2x',
      outputFormat: 'png',
      faceEnhancement: false,
      faceEnhancementStrength: 80,
      faceEnhancementCreativity: 0,
      targetResolution: '1080p',
      targetFps: 30,
      showComparison: true,
      comparisonPosition: 50,
      jobId: null,
    },
  },
  imageGridSplit: {
    type: 'imageGridSplit',
    label: 'Grid Split',
    description: 'Split image into grid cells',
    category: 'processing',
    icon: 'Grid3X3',
    inputs: [{ id: 'image', type: 'image', label: 'Image', required: true }],
    outputs: [{ id: 'images', type: 'image', label: 'Split Images', multiple: true }],
    defaultData: {
      label: 'Grid Split',
      status: 'idle',
      inputImage: null,
      outputImages: [],
      gridRows: 2,
      gridCols: 3,
      borderInset: 10,
      outputFormat: 'jpg',
      quality: 95,
    },
  },
  annotation: {
    type: 'annotation',
    label: 'Annotation',
    description: 'Add shapes, arrows, and text to images',
    category: 'processing',
    icon: 'Pencil',
    inputs: [{ id: 'image', type: 'image', label: 'Image', required: true }],
    outputs: [{ id: 'image', type: 'image', label: 'Annotated Image' }],
    defaultData: {
      label: 'Annotation',
      status: 'idle',
      inputImage: null,
      outputImage: null,
      annotations: [],
      hasAnnotations: false,
    },
  },
  subtitle: {
    type: 'subtitle',
    label: 'Subtitle',
    description: 'Burn subtitles into video using FFmpeg',
    category: 'processing',
    icon: 'Subtitles',
    inputs: [
      { id: 'video', type: 'video', label: 'Video', required: true },
      { id: 'text', type: 'text', label: 'Subtitle Text', required: true },
    ],
    outputs: [{ id: 'video', type: 'video', label: 'Video with Subtitles' }],
    defaultData: {
      label: 'Subtitle',
      status: 'idle',
      inputVideo: null,
      inputText: null,
      outputVideo: null,
      style: 'modern',
      position: 'bottom',
      fontSize: 24,
      fontColor: '#FFFFFF',
      backgroundColor: 'rgba(0,0,0,0.7)',
      fontFamily: 'Arial',
      jobId: null,
    },
  },

  outputGallery: {
    type: 'outputGallery',
    label: 'Output Gallery',
    description: 'Thumbnail grid with lightbox for multi-image outputs',
    category: 'output',
    icon: 'LayoutGrid',
    inputs: [{ id: 'image', type: 'image', label: 'Images', multiple: true }],
    outputs: [],
    defaultData: {
      label: 'Output Gallery',
      status: 'idle',
      images: [],
    },
  },
  imageCompare: {
    type: 'imageCompare',
    label: 'Image Compare',
    description: 'Side-by-side A/B comparison with draggable slider',
    category: 'output',
    icon: 'Columns2',
    inputs: [
      { id: 'image', type: 'image', label: 'Image A' },
      { id: 'image-1', type: 'image', label: 'Image B' },
    ],
    outputs: [],
    defaultData: {
      label: 'Image Compare',
      status: 'idle',
      imageA: null,
      imageB: null,
    },
  },

  // Output nodes
  download: {
    type: 'download',
    label: 'Download',
    description: 'Download workflow output with custom filename',
    category: 'output',
    icon: 'Download',
    inputs: [
      { id: 'image', type: 'image', label: 'Image' },
      { id: 'video', type: 'video', label: 'Video' },
    ],
    outputs: [],
    defaultData: {
      label: 'Download',
      status: 'idle',
      inputImage: null,
      inputVideo: null,
      inputType: null,
      outputName: 'output',
    },
  },

  // Composition nodes (workflow-as-node)
  workflowInput: {
    type: 'workflowInput',
    label: 'Workflow Input',
    description: 'Define an input port for when this workflow is used as a subworkflow',
    category: 'composition',
    icon: 'ArrowRightToLine',
    inputs: [],
    outputs: [{ id: 'value', type: 'image', label: 'Value' }], // Type is dynamic based on inputType
    defaultData: {
      label: 'Workflow Input',
      status: 'idle',
      inputName: 'input',
      inputType: 'image',
      required: true,
      description: '',
    },
  },
  workflowOutput: {
    type: 'workflowOutput',
    label: 'Workflow Output',
    description: 'Define an output port for when this workflow is used as a subworkflow',
    category: 'composition',
    icon: 'ArrowLeftFromLine',
    inputs: [{ id: 'value', type: 'image', label: 'Value', required: true }], // Type is dynamic based on outputType
    outputs: [],
    defaultData: {
      label: 'Workflow Output',
      status: 'idle',
      outputName: 'output',
      outputType: 'image',
      description: '',
      inputValue: null,
    },
  },
  workflowRef: {
    type: 'workflowRef',
    label: 'Subworkflow',
    description: 'Reference another workflow as a subworkflow',
    category: 'composition',
    icon: 'GitBranch',
    inputs: [], // Dynamic based on referenced workflow interface
    outputs: [], // Dynamic based on referenced workflow interface
    defaultData: {
      label: 'Subworkflow',
      status: 'idle',
      referencedWorkflowId: null,
      referencedWorkflowName: null,
      cachedInterface: null,
      inputMappings: {},
      outputMappings: {},
      childExecutionId: null,
    },
  },

  // Multi-format nodes removed - format conversion now handled by schema-driven engine
};

// Explicit ordering for each category (most used first)
export const NODE_ORDER: Record<NodeCategory, NodeType[]> = {
  input: ['imageInput', 'videoInput', 'audioInput', 'prompt', 'promptConstructor'],
  ai: [
    'imageGen',
    'videoGen',
    'llm',
    'lipSync',
    'textToSpeech',
    'transcribe',
    'voiceChange',
    'motionControl',
  ],
  processing: [
    'reframe',
    'upscale',
    'resize',
    'videoStitch',
    'videoTrim',
    'videoFrameExtract',
    'imageGridSplit',
    'annotation',
    'subtitle',
    'animation',
  ],
  output: ['download', 'outputGallery', 'imageCompare'],
  composition: ['workflowRef', 'workflowInput', 'workflowOutput'],
};

// Helper to get nodes by category with explicit ordering
export function getNodesByCategory(): Record<NodeCategory, NodeDefinition[]> {
  const categories: Record<NodeCategory, NodeDefinition[]> = {
    input: [],
    ai: [],
    processing: [],
    output: [],
    composition: [],
  };

  for (const category of Object.keys(NODE_ORDER) as NodeCategory[]) {
    for (const nodeType of NODE_ORDER[category]) {
      const def = NODE_DEFINITIONS[nodeType];
      if (def) {
        categories[category].push(def);
      }
    }
  }

  return categories;
}
